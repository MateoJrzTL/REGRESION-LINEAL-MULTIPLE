library(openxlsx)
DF <- Entrene_R
library(openxlsx)
library(readxl)
Entrene_R <- read_excel("C:/Users/Mateo/Desktop/RLM/Entrene R.xlsx")
View(Entrene_R)
library(REGRESIONLinMul)
Regresion_Lineal_M(DF,DF$calificación)
DF <- Entrene_R
library(REGRESIONLinMul)
Regresion_Lineal_M(DF,DF$calificación)
ajuste <- Regresion_Lineal_M(DF,DF$calificación)
DFx <- DF[,1]
View(DFx)
DFx <- DF[,-1]
View(DFx)
valores_estand <- DFx - mean(DFx)/ sd(DFx)
valores_estand <- (DFx - mean(DFx)/ sd(DFx))
valores_estand <- ((c(DFx) - c(mean(DFx)))/ (sd(DFx)))
z <- as.matrix(DFx)
View(z)
valores_estand <- (z) - mean(z)/ sd(z)
View(valores_estand)
DFs <- valores_estand
Regresion_Lineal_M(DFS,DF$calificación)
Regresion_Lineal_M(DFs,DF$calificación)
Regresion_Lineal_M(DF,DF$calificación)
View(DFs)
View(DFs)
Regresion_Lineal_Ms <- function (X,Y){
#crear la matriz muestra
xz <- as.matrix(cbind(1, X[,-1]))
#estandarizar
x <- as.matrix(xz)-mean(xz)/sd(xz)
#calculamos betas o coeficientes de regresion
beta <- solve(t(x) %*% x) %*% t(x) %*% Y
#calcular el vector de predicciones
y_pred <- x %*% beta
#calcular el error resisudal
error <- Y - y_pred
#calcular la varianza residual
var_residual <- sum(error^2) / (length(Y) - ncol(x))
#calcular la matriz de covarianza de los coeficientes
cov_beta <- var_residual * solve(t(x) %*% x)
#calcular el valor estandar de los coeficientes
se_beta <- sqrt(diag(cov_beta))
#calcular el estadistico t y el valor p para cada coeficiente
t_beta <- beta / se_beta
p_beta <- 2 * pt(abs(t_beta), df = length(Y) - ncol(x), lower.tail = FALSE)
#crear un data frame con los resultados
results <- data.frame(coeficientes = beta, error_estandar = se_beta, t = t_beta, p_valor = p_beta)
row.names(results) <- c("intercepto", colnames(x)[-1])
#calcular el minimo y el maximo
Minimo <- min(error)
Maximo <- max(error)
#calcular el error estandar residual
RSE <- sqrt(var_residual)
#calcular el error de la suma de cuadrados
SCE <- sum(error ^2)
#calcular el promedio de y para funciones proximas
y_prom <- mean(Y)
#calcular la suma total de cuadrados
w <- y_prom - y_pred
w1 <- w^2
src <- sum(w1)
sct <- src + SCE
#clacular r^2 o coeficiente de determinacion
R_square <- src/sct
#calcular r ajustada
obser_variable <- DF[,-1]
K <- NCOL(obser_variable)
r_uno <- (1-R_square)
R_ajusta <- 1-((r_uno) * ((nrow(x)-1) / (nrow(x)-K-1)))
#crear una lista con los valores y resultaados anteriores.
valores <- list("Min"=Minimo,"Max"=Maximo,"Error estandar residual"=RSE,"R2"=R_square,"R ajustada"=R_ajusta, "resultados"=results)
return(valores)
}
Regresion_Lineal_Ms(DF,DF$calificación)
Regresion_Lineal_Ms <- function (X,Y){
#crear la matriz muestra
xz <- as.matrix(cbind(1, X[,-1]))
#estandarizar
x <- ((xz)-mean(xz))/sd(xz)
#calculamos betas o coeficientes de regresion
beta <- solve(t(x) %*% x) %*% t(x) %*% Y
#calcular el vector de predicciones
y_pred <- x %*% beta
#calcular el error resisudal
error <- Y - y_pred
#calcular la varianza residual
var_residual <- sum(error^2) / (length(Y) - ncol(x))
#calcular la matriz de covarianza de los coeficientes
cov_beta <- var_residual * solve(t(x) %*% x)
#calcular el valor estandar de los coeficientes
se_beta <- sqrt(diag(cov_beta))
#calcular el estadistico t y el valor p para cada coeficiente
t_beta <- beta / se_beta
p_beta <- 2 * pt(abs(t_beta), df = length(Y) - ncol(x), lower.tail = FALSE)
#crear un data frame con los resultados
results <- data.frame(coeficientes = beta, error_estandar = se_beta, t = t_beta, p_valor = p_beta)
row.names(results) <- c("intercepto", colnames(x)[-1])
#calcular el minimo y el maximo
Minimo <- min(error)
Maximo <- max(error)
#calcular el error estandar residual
RSE <- sqrt(var_residual)
#calcular el error de la suma de cuadrados
SCE <- sum(error ^2)
#calcular el promedio de y para funciones proximas
y_prom <- mean(Y)
#calcular la suma total de cuadrados
w <- y_prom - y_pred
w1 <- w^2
src <- sum(w1)
sct <- src + SCE
#clacular r^2 o coeficiente de determinacion
R_square <- src/sct
#calcular r ajustada
obser_variable <- DF[,-1]
K <- NCOL(obser_variable)
r_uno <- (1-R_square)
R_ajusta <- 1-((r_uno) * ((nrow(x)-1) / (nrow(x)-K-1)))
#crear una lista con los valores y resultaados anteriores.
valores <- list("Min"=Minimo,"Max"=Maximo,"Error estandar residual"=RSE,"R2"=R_square,"R ajustada"=R_ajusta, "resultados"=results)
return(valores)
}
Regresion_Lineal_Ms(DF,DF$calificación)
mean(xz)
Regresion_Lineal_Ms <- function (X,Y){
s <- as.matrix(X - mean(X)/sd(X))
#crear la matriz muestra
x <- as.matrix(cbind(1, s[,-1]))
#calculamos betas o coeficientes de regresion
beta <- solve(t(x) %*% x) %*% t(x) %*% Y
#calcular el vector de predicciones
y_pred <- x %*% beta
#calcular el error resisudal
error <- Y - y_pred
#calcular la varianza residual
var_residual <- sum(error^2) / (length(Y) - ncol(x))
#calcular la matriz de covarianza de los coeficientes
cov_beta <- var_residual * solve(t(x) %*% x)
#calcular el valor estandar de los coeficientes
se_beta <- sqrt(diag(cov_beta))
#calcular el estadistico t y el valor p para cada coeficiente
t_beta <- beta / se_beta
p_beta <- 2 * pt(abs(t_beta), df = length(Y) - ncol(x), lower.tail = FALSE)
#crear un data frame con los resultados
results <- data.frame(coeficientes = beta, error_estandar = se_beta, t = t_beta, p_valor = p_beta)
row.names(results) <- c("intercepto", colnames(x)[-1])
#calcular el minimo y el maximo
Minimo <- min(error)
Maximo <- max(error)
#calcular el error estandar residual
RSE <- sqrt(var_residual)
#calcular el error de la suma de cuadrados
SCE <- sum(error ^2)
#calcular el promedio de y para funciones proximas
y_prom <- mean(Y)
#calcular la suma total de cuadrados
w <- y_prom - y_pred
w1 <- w^2
src <- sum(w1)
sct <- src + SCE
#clacular r^2 o coeficiente de determinacion
R_square <- src/sct
#calcular r ajustada
obser_variable <- DF[,-1]
K <- NCOL(obser_variable)
r_uno <- (1-R_square)
R_ajusta <- 1-((r_uno) * ((nrow(x)-1) / (nrow(x)-K-1)))
#crear una lista con los valores y resultaados anteriores.
valores <- list("Min"=Minimo,"Max"=Maximo,"Error estandar residual"=RSE,"R2"=R_square,"R ajustada"=R_ajusta, "resultados"=results)
return(valores)
}
Regresion_Lineal_Ms(DF,DF$calificación)
Regresion_Lineal_Ms <- function (X,Y){
s <- as.matrix((X - mean(X))/sd(X))
#crear la matriz muestra
x <- as.matrix(cbind(1, s[,-1]))
#calculamos betas o coeficientes de regresion
beta <- solve(t(x) %*% x) %*% t(x) %*% Y
#calcular el vector de predicciones
y_pred <- x %*% beta
#calcular el error resisudal
error <- Y - y_pred
#calcular la varianza residual
var_residual <- sum(error^2) / (length(Y) - ncol(x))
#calcular la matriz de covarianza de los coeficientes
cov_beta <- var_residual * solve(t(x) %*% x)
#calcular el valor estandar de los coeficientes
se_beta <- sqrt(diag(cov_beta))
#calcular el estadistico t y el valor p para cada coeficiente
t_beta <- beta / se_beta
p_beta <- 2 * pt(abs(t_beta), df = length(Y) - ncol(x), lower.tail = FALSE)
#crear un data frame con los resultados
results <- data.frame(coeficientes = beta, error_estandar = se_beta, t = t_beta, p_valor = p_beta)
row.names(results) <- c("intercepto", colnames(x)[-1])
#calcular el minimo y el maximo
Minimo <- min(error)
Maximo <- max(error)
#calcular el error estandar residual
RSE <- sqrt(var_residual)
#calcular el error de la suma de cuadrados
SCE <- sum(error ^2)
#calcular el promedio de y para funciones proximas
y_prom <- mean(Y)
#calcular la suma total de cuadrados
w <- y_prom - y_pred
w1 <- w^2
src <- sum(w1)
sct <- src + SCE
#clacular r^2 o coeficiente de determinacion
R_square <- src/sct
#calcular r ajustada
obser_variable <- DF[,-1]
K <- NCOL(obser_variable)
r_uno <- (1-R_square)
R_ajusta <- 1-((r_uno) * ((nrow(x)-1) / (nrow(x)-K-1)))
#crear una lista con los valores y resultaados anteriores.
valores <- list("Min"=Minimo,"Max"=Maximo,"Error estandar residual"=RSE,"R2"=R_square,"R ajustada"=R_ajusta, "resultados"=results)
return(valores)
}
Regresion_Lineal_Ms(DF,DF$calificación)
Regresion_Lineal_Ms <- function (X,Y){
s <- (X - mean(X))/sd(X)
#crear la matriz muestra
x <- as.matrix(cbind(1, s[,-1]))
#calculamos betas o coeficientes de regresion
beta <- solve(t(x) %*% x) %*% t(x) %*% Y
#calcular el vector de predicciones
y_pred <- x %*% beta
#calcular el error resisudal
error <- Y - y_pred
#calcular la varianza residual
var_residual <- sum(error^2) / (length(Y) - ncol(x))
#calcular la matriz de covarianza de los coeficientes
cov_beta <- var_residual * solve(t(x) %*% x)
#calcular el valor estandar de los coeficientes
se_beta <- sqrt(diag(cov_beta))
#calcular el estadistico t y el valor p para cada coeficiente
t_beta <- beta / se_beta
p_beta <- 2 * pt(abs(t_beta), df = length(Y) - ncol(x), lower.tail = FALSE)
#crear un data frame con los resultados
results <- data.frame(coeficientes = beta, error_estandar = se_beta, t = t_beta, p_valor = p_beta)
row.names(results) <- c("intercepto", colnames(x)[-1])
#calcular el minimo y el maximo
Minimo <- min(error)
Maximo <- max(error)
#calcular el error estandar residual
RSE <- sqrt(var_residual)
#calcular el error de la suma de cuadrados
SCE <- sum(error ^2)
#calcular el promedio de y para funciones proximas
y_prom <- mean(Y)
#calcular la suma total de cuadrados
w <- y_prom - y_pred
w1 <- w^2
src <- sum(w1)
sct <- src + SCE
#clacular r^2 o coeficiente de determinacion
R_square <- src/sct
#calcular r ajustada
obser_variable <- DF[,-1]
K <- NCOL(obser_variable)
r_uno <- (1-R_square)
R_ajusta <- 1-((r_uno) * ((nrow(x)-1) / (nrow(x)-K-1)))
#crear una lista con los valores y resultaados anteriores.
valores <- list("Min"=Minimo,"Max"=Maximo,"Error estandar residual"=RSE,"R2"=R_square,"R ajustada"=R_ajusta, "resultados"=results)
return(valores)
}
Regresion_Lineal_Ms(DF,DF$calificación)
estandarizacion <- (DF[,-1]-mean(DF[-1]))/sd(DF[,-1])
sd(DF[,-1])
W <-DF[,-1]
sd(W)
W <-c(DF[,-1])
View(W)
W[["califExam"]]
sd(W)
W <-c(DF[,1])
View(W)
sd(W)
W <-DF[,1]
sd(W)
View(W)
sdx <- DF[,1]-min(DF[,1]) / max(DF) - min(DF)
View(sdx)
sdf <- DF[,1]-mean(DF[,1])/ sd(DF[,1])
sdx <- DF[,1]-min(DF[,1]) / max(DF[,1]) - min(DF[,1])
View(sdx)
X1 <- DF[,2]-min(DF[,2]) / max(DF[,2]) - min(DF[,2])
x2 <- DF[,3]-min(DF[,3]) / max(DF[,3]) - min(DF[,3])
Y <- DF[,1]
DFSZ <- data.frame(Y,X1,X2)
X1 <- DF[,2]-min(DF[,2]) / max(DF[,2]) - min(DF[,2])
X2 <- DF[,3]-min(DF[,3]) / max(DF[,3]) - min(DF[,3])
Y <- DF[,1]
DFSZ <- data.frame(Y,X1,X2)
DFSZ
Regresion_Lineal_Ms <- function (X,Y){
#crear la matriz muestra
x <- as.matrix(cbind(1, X[,-1]))
#calculamos betas o coeficientes de regresion
beta <- solve(t(x) %*% x) %*% t(x) %*% Y
#calcular el vector de predicciones
y_pred <- x %*% beta
#calcular el error resisudal
error <- Y - y_pred
#calcular la varianza residual
var_residual <- sum(error^2) / (length(Y) - ncol(x))
#calcular la matriz de covarianza de los coeficientes
cov_beta <- var_residual * solve(t(x) %*% x)
#calcular el valor estandar de los coeficientes
se_beta <- sqrt(diag(cov_beta))
#calcular el estadistico t y el valor p para cada coeficiente
t_beta <- beta / se_beta
p_beta <- 2 * pt(abs(t_beta), df = length(Y) - ncol(x), lower.tail = FALSE)
#crear un data frame con los resultados
results <- data.frame(coeficientes = beta, error_estandar = se_beta, t = t_beta, p_valor = p_beta)
row.names(results) <- c("intercepto", colnames(x)[-1])
#calcular el minimo y el maximo
Minimo <- min(error)
Maximo <- max(error)
#calcular el error estandar residual
RSE <- sqrt(var_residual)
#calcular el error de la suma de cuadrados
SCE <- sum(error ^2)
#calcular el promedio de y para funciones proximas
y_prom <- mean(Y)
#calcular la suma total de cuadrados
w <- y_prom - y_pred
w1 <- w^2
src <- sum(w1)
sct <- src + SCE
#clacular r^2 o coeficiente de determinacion
R_square <- src/sct
#calcular r ajustada
obser_variable <- DF[,-1]
K <- NCOL(obser_variable)
r_uno <- (1-R_square)
R_ajusta <- 1-((r_uno) * ((nrow(x)-1) / (nrow(x)-K-1)))
#crear una lista con los valores y resultaados anteriores.
valores <- list("Min"=Minimo,"Max"=Maximo,"Error estandar residual"=RSE,"R2"=R_square,"R ajustada"=R_ajusta, "resultados"=results)
return(valores)
}
View(DFSZ)
Regresion_Lineal_Ms(DFSZ,DFSZ$calificación)
library(readxl)
Datos_para_redicciones <- read_excel("C:/Users/Mateo/Desktop/ProbandoPaquete/Datos para redicciones.xlsx")
View(Datos_para_redicciones)
DF2 <- Datos_para_redicciones
X1 <- DF2[,1]-min(DF2[,1]) / max(DF2[,1]) - min(DF2[,1])
X2 <- DF2[,2]-min(DF2[,2]) / max(DF2[,2]) - min(DF2[,2])
DFSZ2 <- data.frame(X1,X2)
ajuste <- Regresion_Lineal_Ms(DFSZ,DFSZ$calificación)
predicción(DFSZ2,ajuste)
View(DFSZ2)
y1<- DF[,1]-min(DF[,1]) / max(DF[,1]) - min(DF[,1])
X12 <- DF[,2]-min(DF[,2]) / max(DF[,2]) - min(DF[,2])
X13 <- DF[,3]-min(DF[,3]) / max(DF[,3]) - min(DF[,3])
library(openxlsx)
library(readxl)
Datos_para_redicciones <- read_excel("C:/Users/Mateo/Desktop/ProbandoPaquete/Datos para redicciones.xlsx")
View(Datos_para_redicciones)
DF2 <- Datos_para_redicciones
library(readxl)
Entrene_R <- read_excel("C:/Users/Mateo/Desktop/RLM/Entrene R.xlsx")
View(Entrene_R)
DF <- Entrene_R
y1<- DF[,1]-min(DF[,1]) / max(DF[,1]) - min(DF[,1])
X12 <- DF[,2]-min(DF[,2]) / max(DF[,2]) - min(DF[,2])
X13 <- DF[,3]-min(DF[,3]) / max(DF[,3]) - min(DF[,3])
X1 <- DF2[,2]-min(DF2[,2]) / max(DF2[,2]) - min(DF2[,2])
X2 <- DF2[,3]-min(DF2[,3]) / max(DF2[,3]) - min(DF2[,3])
y1<- DF[,1]-min(DF[,1]) / max(DF[,1]) - min(DF[,1])
X12 <- DF[,2]-min(DF[,2]) / max(DF[,2]) - min(DF[,2])
X13 <- DF[,3]-min(DF[,3]) / max(DF[,3]) - min(DF[,3])
X1 <- DF2[,1]-min(DF2[,1]) / max(DF2[,1]) - min(DF2[,1])
X2 <- DF2[,2]-min(DF2[,2]) / max(DF2[,2]) - min(DF2[,2])
DF1 <- data.frame(y,X12,X13)
DF1 <- data.frame(y1,X12,X13)
View(DF1)
DF12 <- data.frame(x1,x2)
Regresion_Lineal_Ms <- function (X,Y){
#crear la matriz muestra
x <- as.matrix(cbind(1, X[,-1]))
#calculamos betas o coeficientes de regresion
beta <- solve(t(x) %*% x) %*% t(x) %*% Y
#calcular el vector de predicciones
y_pred <- x %*% beta
#calcular el error resisudal
error <- Y - y_pred
#calcular la varianza residual
var_residual <- sum(error^2) / (length(Y) - ncol(x))
#calcular la matriz de covarianza de los coeficientes
cov_beta <- var_residual * solve(t(x) %*% x)
#calcular el valor estandar de los coeficientes
se_beta <- sqrt(diag(cov_beta))
#calcular el estadistico t y el valor p para cada coeficiente
t_beta <- beta / se_beta
p_beta <- 2 * pt(abs(t_beta), df = length(Y) - ncol(x), lower.tail = FALSE)
#crear un data frame con los resultados
results <- data.frame(coeficientes = beta, error_estandar = se_beta, t = t_beta, p_valor = p_beta)
row.names(results) <- c("intercepto", colnames(x)[-1])
#calcular el minimo y el maximo
Minimo <- min(error)
Maximo <- max(error)
#calcular el error estandar residual
RSE <- sqrt(var_residual)
#calcular el error de la suma de cuadrados
SCE <- sum(error ^2)
#calcular el promedio de y para funciones proximas
y_prom <- mean(Y)
#calcular la suma total de cuadrados
w <- y_prom - y_pred
w1 <- w^2
src <- sum(w1)
sct <- src + SCE
#clacular r^2 o coeficiente de determinacion
R_square <- src/sct
#calcular r ajustada
obser_variable <- DF[,-1]
K <- NCOL(obser_variable)
r_uno <- (1-R_square)
R_ajusta <- 1-((r_uno) * ((nrow(x)-1) / (nrow(x)-K-1)))
#crear una lista con los valores y resultaados anteriores.
valores <- list("Min"=Minimo,"Max"=Maximo,"Error estandar residual"=RSE,"R2"=R_square,"R ajustada"=R_ajusta, "resultados"=results)
return(valores)
}
ajuste <- Regresion_Lineal_Ms(DF1,DF1$calificación)
View(ajuste)
ajuste[["Min"]]
ajuste[["resultados"]]
predicción(DF12,ajuste)
DF12 <- data.frame(x1,x2)
predicción(DF12,ajuste)
DF12 <- data.frame(x1,x2)
DF12 <- data.frame(x1,x2)
DFx2 <- data.frame(x1,x2)
X1 <- DF2[,1]-min(DF2[,1]) / max(DF2[,1]) - min(DF2[,1])
X2 <- DF2[,2]-min(DF2[,2]) / max(DF2[,2]) - min(DF2[,2])
DFx2 <- data.frame(x1,x2)
predicción(DF2,ajuste)
View(DF2)
D<-data.frame(x1,x2)
